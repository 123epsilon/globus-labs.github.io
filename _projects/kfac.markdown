---
layout: project
title:  "Distributed K-FAC"
image: "kfac.png"
teaser: "Deep Neural Network Training with Distributed K-FAC"
featured: false
description: "Kronecker-factored Approximate Curvature (K-FAC) can enable efficient second-order optimization and faster deep neural network training than traditional optimizers (e.g., SGD). Distributed K-FAC performs the expensive second-order computations in a model-parallel method to efficiently utilize HPC resources."
---

Try it out on [GitHub](https://github.com/gpauloski/kfac_pytorch).

Publications:
- J. Gregory Pauloski, Zhao Zhang, Lei Huang, Weijia Xu, and Ian T. Foster. 2020. [Convolutional neural network training with distributed K-FAC](https://arxiv.org/pdf/2007.00784.pdf). In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC ‘20). IEEE Press, Article 94, 1–14.
